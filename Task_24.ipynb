{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E4vdXFRCMPrx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# Load the California housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "y = pd.Series(housing.target)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "ukXLxNeR-V8T"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean Absolute Error (MAE)\n",
        "Description: MAE measures the average magnitude of the errors in a set of predictions, without considering their direction. It is the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight.\n",
        "\n",
        "Lower MAE indicates better model performance. It is intuitive and easy to understand as it gives an average of the absolute errors. However, it does not penalize larger errors as much as MSE."
      ],
      "metadata": {
        "id": "jpgr_WJ7-cIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error (MAE): {mae}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iu3R64o-Y8u",
        "outputId": "6dc558c5-6bfc-4b56-cfb2-63cce003fc6b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.5332001304956553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean Squared Error (MSE)\n",
        "Description: MSE measures the average of the squares of the errors. It is the average squared difference between the estimated values and the actual value.\n",
        "\n",
        "Lower MSE indicates better model performance. MSE is more sensitive to outliers than MAE because it squares the errors, which means that larger errors have a disproportionately larger effect on the metric."
      ],
      "metadata": {
        "id": "uuizDh5O-iJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error (MSE): {mse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVUJE5cH-tNA",
        "outputId": "db3df216-e6de-4923-b5b1-da584d5adc02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.5558915986952444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Root Mean Squared Error (RMSE)\n",
        "Description: RMSE is the square root of the mean squared error. It provides an error estimate in the same units as the target variable, making it more interpretable than MSE.\n",
        "\n",
        "Lower RMSE indicates better model performance. RMSE is particularly useful when large errors are undesirable.\n"
      ],
      "metadata": {
        "id": "jl0Tg8Fx-v44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GGyaXwt-0wV",
        "outputId": "6f4996e0-4652-41d8-dcb8-31c3f9f56455"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 0.7455813830127764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# R-squared (R²)\n",
        "Description: R-squared, or the coefficient of determination, indicates the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
        "\n",
        "Ranges from 0 to 1. Higher values indicate better model performance, with 1 indicating that the model explains all the variability of the response data around its mean. However, R² can sometimes be misleading for models with many predictors."
      ],
      "metadata": {
        "id": "aqsen4MV-4Z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'R-squared (R²): {r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZneDfqe-89U",
        "outputId": "1e1e18bf-254b-48fe-b45b-a8af22cc1dcc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared (R²): 0.5757877060324508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adjusted R-squared\n",
        "Description: Adjusted R-squared adjusts the R-squared value based on the number of predictors in the model, providing a more accurate measure for multiple regression models. It accounts for the diminishing returns of adding more predictors.\n",
        "\n",
        "Higher values indicate better model performance. Adjusted R-squared is useful for comparing models with different numbers of predictors as it penalizes the addition of irrelevant predictors."
      ],
      "metadata": {
        "id": "QvnWvQ6Y_ANJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adjusted_r2_score(y_true, y_pred, n, p):\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "\n",
        "\n",
        "n = len(y_test)\n",
        "p = X_test.shape[1]\n",
        "adjusted_r2 = adjusted_r2_score(y_test, y_pred, n, p)\n",
        "print(f'Adjusted R-squared: {adjusted_r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snGJLKqM_ErU",
        "outputId": "bce67c41-768e-4e34-eb3e-5887daa1465d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusted R-squared: 0.5749637928613558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean Absolute Percentage Error (MAPE)\n",
        "Description: MAPE measures the accuracy of predictions as a percentage. It is useful for understanding the error in relative terms.\n",
        "\n",
        "Lower MAPE indicates better model performance. It is expressed as a percentage, making it easier to interpret in some contexts. However, it can be problematic when actual values are very close to zero."
      ],
      "metadata": {
        "id": "IEkK1EQ5_H5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Percentage Error (MAPE): {mape}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx85MaDU_UTj",
        "outputId": "91072df8-36e6-4a0d-b4f1-fa0ed56d4a57"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Percentage Error (MAPE): 31.95218741361489%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Median Absolute Error\n",
        "Description: Median absolute error provides a robust measure of the central tendency of errors, less influenced by outliers than MAE. It is the median of all absolute errors.\n",
        "\n",
        "Lower median absolute error indicates better model performance. It is particularly useful when the dataset contains outliers that might skew the mean error metrics.\n"
      ],
      "metadata": {
        "id": "PzljFvcn_XYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "median_ae = median_absolute_error(y_test, y_pred)\n",
        "print(f'Median Absolute Error: {median_ae}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZNua07T_cYe",
        "outputId": "cadaf241-3174-4217-dedd-65b4d2b94d88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median Absolute Error: 0.41023300084958947\n"
          ]
        }
      ]
    }
  ]
}