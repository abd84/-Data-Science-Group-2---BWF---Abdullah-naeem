{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jNdOPxIEAN6I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=100,\n",
        "    n_features=2,\n",
        "    n_informative=2,  # Number of informative features\n",
        "    n_redundant=0,    # Number of redundant features\n",
        "    n_repeated=0,     # Number of repeated features\n",
        "    n_classes=2,\n",
        "    random_state=42\n",
        ")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "A statistical model used to predict the probability of a binary outcome. It estimates the parameters of a logistic function to output probabilities that are then mapped to class labels."
      ],
      "metadata": {
        "id": "ww67tZ5vCPXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn-IeGcDB4BU",
        "outputId": "656867cd-65b0-4a59-fb85-1f8692f5c6c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# k-Nearest Neighbors (k-NN)\n",
        "A non-parametric method that classifies a data point based on the majority class among its 'k' nearest neighbors in the feature space. It relies on the distance metric (e.g., Euclidean distance)."
      ],
      "metadata": {
        "id": "9EuPc8pUCSOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "print(\"k-NN Accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ear4VFcuB4nS",
        "outputId": "b7faf7fe-6688-47bb-a8f5-03d9c5fd3963"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-NN Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machine (SVM)\n",
        "Finds the optimal hyperplane that separates classes with the maximum margin. It can handle both linear and non-linear classification using different kernel functions."
      ],
      "metadata": {
        "id": "BNenOQ3LCZpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVC(kernel='linear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34iP5xZXB8W2",
        "outputId": "813e5e5b-3448-4d75-a18e-6f1bcb82d43e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree\n",
        " A model that splits data into subsets based on feature values, creating a tree-like structure of decisions. Each node represents a decision rule, and each branch represents the outcome of that rule."
      ],
      "metadata": {
        "id": "H318cIMICedE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz8iBeVqB-Li",
        "outputId": "9d2705a6-7054-4455-fcf9-d54dc4e42c35"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest\n",
        "An ensemble method that constructs multiple decision trees and aggregates their predictions. It reduces overfitting and improves accuracy by averaging the results from multiple trees."
      ],
      "metadata": {
        "id": "3MVSRetHCmY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqQtwEomB_mr",
        "outputId": "57a9c4c1-51ff-4717-ebfd-331ab42c3f0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting\n",
        "A boosting technique that builds models sequentially, with each new model correcting the errors of its predecessor. This improves performance by focusing on difficult cases."
      ],
      "metadata": {
        "id": "cJpk0KFmCrdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GradientBoostingClassifier(n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaBqTLNTCBMx",
        "outputId": "cc2dbeb3-7bee-4e48-f66a-9134da812987"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes\n",
        "A probabilistic classifier based on Bayes' theorem with the assumption of feature independence given the class label. It calculates the probability of each class and selects the class with the highest probability."
      ],
      "metadata": {
        "id": "FDqxBe_YCuq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUzJ-ihLCC_G",
        "outputId": "4f1a933f-8b8f-4768-cd02-136dcdbc8d1f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    }
  ]
}