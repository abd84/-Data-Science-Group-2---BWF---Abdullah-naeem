{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter\n",
        "tuning is a crucial step in optimizing machine learning models. It involves selecting the best set of hyperparameters to improve a model's performance. Here are some common hyperparameter tuning techniques:\n",
        "\n",
        "# Grid Search:\n",
        "Grid Search exhaustively searches over a specified parameter grid to find the best combination of hyperparameters.\n",
        "It evaluates all possible combinations of hyperparameters to determine the best one based on cross-validation performance.\n",
        "# Random Search:\n",
        "Random Search randomly samples a specified number of hyperparameter combinations from a grid.\n",
        "It is more efficient than Grid Search because it does not evaluate all possible combinations, making it faster and often finding good hyperparameters with fewer iterations.\n",
        "# Bayesian Optimization:\n",
        "Bayesian Optimization builds a probabilistic model of the function mapping hyperparameters to the objective score (e.g., accuracy).\n",
        "It iteratively updates the model with new hyperparameter sets, balancing exploration and exploitation to find the optimal set efficiently."
      ],
      "metadata": {
        "id": "RZ-w6LFuh43Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lQsRGJf-hs0b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "vT8tzptPiFPa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier()\n",
        "\n",
        "# Define hyperparameter grid for Grid Search\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Define hyperparameter grid for Random Search\n",
        "param_dist = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10, 15, 20]\n",
        "}\n"
      ],
      "metadata": {
        "id": "y06D8qaniG-2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_grid = grid_search.best_estimator_\n",
        "y_pred = best_grid.predict(X_test)\n",
        "print(f'Grid Search Best Parameters: {grid_search.best_params_}')\n",
        "print(f'Grid Search Accuracy: {accuracy_score(y_test, y_pred)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR3tqG-viJnH",
        "outputId": "c2259840-59b3-427b-d49c-1f16fe1080db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid Search Best Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 10}\n",
            "Grid Search Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, cv=5, n_jobs=-1, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_random = random_search.best_estimator_\n",
        "y_pred = best_random.predict(X_test)\n",
        "print(f'Random Search Best Parameters: {random_search.best_params_}')\n",
        "print(f'Random Search Accuracy: {accuracy_score(y_test, y_pred)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIx6oitViLdT",
        "outputId": "dd9445ff-a925-48dd-f102-51ea4a29ba05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Search Best Parameters: {'n_estimators': 50, 'min_samples_split': 10, 'max_depth': 40}\n",
            "Random Search Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Bayesian Optimization, we can use libraries like hyperopt:\n",
        "\n",
        "\n",
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective(params):\n",
        "    model = RandomForestClassifier(**params)\n",
        "    accuracy = cross_val_score(model, X_train, y_train, cv=5).mean()\n",
        "    return {'loss': -accuracy, 'status': STATUS_OK}\n",
        "\n",
        "param_space = {\n",
        "    'n_estimators': hp.choice('n_estimators', [10, 50, 100, 200]),\n",
        "    'max_depth': hp.choice('max_depth', [None, 10, 20, 30, 40, 50]),\n",
        "    'min_samples_split': hp.choice('min_samples_split', [2, 5, 10, 15, 20])\n",
        "}\n",
        "\n",
        "trials = Trials()\n",
        "best_params = fmin(fn=objective, space=param_space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
        "\n",
        "# Convert best_params back to the values used in model\n",
        "best_params['n_estimators'] = [10, 50, 100, 200][best_params['n_estimators']]\n",
        "best_params['max_depth'] = [None, 10, 20, 30, 40, 50][best_params['max_depth']]\n",
        "best_params['min_samples_split'] = [2, 5, 10, 15, 20][best_params['min_samples_split']]\n",
        "\n",
        "best_bayes = RandomForestClassifier(**best_params)\n",
        "best_bayes.fit(X_train, y_train)\n",
        "y_pred = best_bayes.predict(X_test)\n",
        "print(f'Bayesian Optimization Best Parameters: {best_params}')\n",
        "print(f'Bayesian Optimization Accuracy: {accuracy_score(y_test, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtbqYK-jiQKo",
        "outputId": "a0f0360a-b679-46b8-90b3-7204fb72e7a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 50/50 [00:37<00:00,  1.34trial/s, best loss: -0.9523809523809523]\n",
            "Bayesian Optimization Best Parameters: {'max_depth': 50, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Bayesian Optimization Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}